{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94g3zsK5RykJ",
        "outputId": "fa83387e-5a01-4281-a356-9be2afa849a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix for Logistic Regression:\n",
            "[[1552   41]\n",
            " [ 349   58]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89      1593\n",
            "           1       0.59      0.14      0.23       407\n",
            "\n",
            "    accuracy                           0.81      2000\n",
            "   macro avg       0.70      0.56      0.56      2000\n",
            "weighted avg       0.77      0.81      0.75      2000\n",
            "\n",
            "\n",
            "Confusion Matrix for Decision Tree:\n",
            "[[1357  236]\n",
            " [ 213  194]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.86      1593\n",
            "           1       0.45      0.48      0.46       407\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.66      0.66      0.66      2000\n",
            "weighted avg       0.78      0.78      0.78      2000\n",
            "\n",
            "\n",
            "Confusion Matrix for KNN:\n",
            "[[1513   80]\n",
            " [ 250  157]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90      1593\n",
            "           1       0.66      0.39      0.49       407\n",
            "\n",
            "    accuracy                           0.83      2000\n",
            "   macro avg       0.76      0.67      0.69      2000\n",
            "weighted avg       0.82      0.83      0.82      2000\n",
            "\n",
            "\n",
            "Confusion Matrix for Naive Bayes:\n",
            "[[1562   31]\n",
            " [ 311   96]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.98      0.90      1593\n",
            "           1       0.76      0.24      0.36       407\n",
            "\n",
            "    accuracy                           0.83      2000\n",
            "   macro avg       0.79      0.61      0.63      2000\n",
            "weighted avg       0.82      0.83      0.79      2000\n",
            "\n",
            "\n",
            "Confusion Matrix for Random Forest:\n",
            "[[1542   51]\n",
            " [ 220  187]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92      1593\n",
            "           1       0.79      0.46      0.58       407\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.83      0.71      0.75      2000\n",
            "weighted avg       0.86      0.86      0.85      2000\n",
            "\n",
            "\n",
            "Confusion Matrix for XGBoost:\n",
            "[[1502   91]\n",
            " [ 215  192]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.91      1593\n",
            "           1       0.68      0.47      0.56       407\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.78      0.71      0.73      2000\n",
            "weighted avg       0.83      0.85      0.84      2000\n",
            "\n",
            "\n",
            "Model Performance Comparison:\n",
            "\n",
            "                     Accuracy     AUC  Precision  Recall  F1 Score     MCC\n",
            "Logistic Regression    0.8050  0.7710     0.5859  0.1425    0.2292  0.2167\n",
            "Decision Tree          0.7755  0.6643     0.4512  0.4767    0.4636  0.3219\n",
            "KNN                    0.8350  0.7724     0.6624  0.3857    0.4876  0.4180\n",
            "Naive Bayes            0.8290  0.8146     0.7559  0.2359    0.3596  0.3573\n",
            "Random Forest          0.8645  0.8469     0.7857  0.4595    0.5798  0.5315\n",
            "XGBoost                0.8470  0.8330     0.6784  0.4717    0.5565  0.4789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:31:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, precision_score,\n",
        "    recall_score, f1_score, matthews_corrcoef\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# ===============================\n",
        "# Load Dataset\n",
        "# ===============================\n",
        "df = pd.read_csv(\"/content/Churn_Modelling.csv\")\n",
        "\n",
        "# ===============================\n",
        "# Drop unnecessary columns\n",
        "# ===============================\n",
        "df.drop(columns=[\"RowNumber\", \"CustomerId\", \"Surname\"], inplace=True)\n",
        "\n",
        "# ===============================\n",
        "# Encode categorical features\n",
        "# ===============================\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"Gender\"] = label_encoder.fit_transform(df[\"Gender\"])\n",
        "df[\"Geography\"] = label_encoder.fit_transform(df[\"Geography\"])\n",
        "\n",
        "# ===============================\n",
        "# Split features and target\n",
        "# ===============================\n",
        "X = df.drop(\"Exited\", axis=1)\n",
        "y = df[\"Exited\"]\n",
        "\n",
        "# ===============================\n",
        "# Train-Test Split\n",
        "# ===============================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# Feature Scaling\n",
        "# ===============================\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Save scaler for Streamlit\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "joblib.dump(scaler, \"model/scaler.pkl\")\n",
        "\n",
        "# ===============================\n",
        "# Models\n",
        "# ===============================\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# ===============================\n",
        "# Evaluation Function\n",
        "# ===============================\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Metrics\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"AUC\": roc_auc_score(y_test, y_prob),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1 Score\": f1_score(y_test, y_pred),\n",
        "        \"MCC\": matthews_corrcoef(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"\\nConfusion Matrix for {model_name}:\")\n",
        "    print(cm)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Train, Evaluate, Save Models\n",
        "# ===============================\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    metrics = evaluate_model(model, X_test, y_test,name)\n",
        "    results[name] = metrics\n",
        "\n",
        "    # Save model\n",
        "    filename = name.lower().replace(\" \", \"_\") + \".pkl\"\n",
        "    joblib.dump(model, f\"model/{filename}\")\n",
        "\n",
        "# ===============================\n",
        "# Display Results\n",
        "# ===============================\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nModel Performance Comparison:\\n\")\n",
        "print(results_df.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "crryFRYdSJCz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
